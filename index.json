[{"content":"Deepspeed多机多卡训练记录\n如果用到fp16等半精度训练，需要安装nvidia的apex。\n步骤：\n先让两台机可以ssh通信，在主节点执行ssh-keygen，可以一直回车，生成的密钥在/home/你的用户名/.ssh/下，需要把公钥id_rsa.pub传到子节点的对应.ssh文件夹下，并且重命名为authorized_keys，私钥保留在本地即可。\n一定要注意：主节点上也需要将id_rsa.pub 拷贝成authorized_keys！！！\n随后可以ssh连接子节点测试一下，不需要输入密码也可以连接。\n在系统层面安装pdsh来帮助nccl通信，在我这里使用的debian直接apt安装就可以了。\n我这里主从系统配置了完全一样的系统、conda环境、conda虚拟环境名称，代码路径，代码完全保持一致。\n配置hostfile，格式为：192.168.x.xx slots=2；前面是标注机器，注意主机要放到第一行，slot代表每台机显卡数量。\n可以通过DeepSpeed/DeepSpeedExamples/pipeline_parallelism这个例子进行单机多卡、多机多卡测试，区别是多级多卡测试需要加一行\u0026ndash;hostfile=hostfile。\n遇到的问题：\ncannot import name \u0026lsquo;UnencryptedCookieSessionFactoryConfig\u0026rsquo; from \u0026lsquo;pyramid.session\u0026rsquo; (unknown location)\n问题定位：不要pip install apex，这不是nVidia的apex，需要去github下载。\n解决方法：GitHub - NVIDIA/apex: A PyTorch Extension: Tools for easy mixed precision and distributed training in Pytorch 在这里安装。\nModuleNotFoundError: No module named \u0026lsquo;fused_layer_norm_cuda\u0026rsquo;\n问题定位：apex和cuda/pytorch不匹配，apex代码错误等都有可能出现。\n解决方案：我这里是根据github的apex issue重新下载了符合pytorch版本的apex版本重新编译就好了。\n​\t3. proxy call to rank 1 failed (connect)\n​\t问题定位：NCCL机器通讯问题\n​\t解决方案：\n​\texport NCCL_DEBUG=INFO ​\texport NCCL_IB_DISABLE=1 ​\texport NCCL_SOCKET_IFNAME=网卡名字\nNinja is required to load C++ extensions ​\t问题定位：Ninja找不到path中的C++库位置\n​\t解决方案：\nimport os new_env = os.environ.copy() new_env [\u0026#34;PATH\u0026#34;] = \u0026#34;/本地conda环境/bin:\u0026#34; + new_env [\u0026#34;PATH\u0026#34;] os.environ.update(new_env ) ","permalink":"https://boringleric.github.io/posts/tech/deepspeed_multinode_multicard/","summary":"Deepspeed多机多卡训练记录 如果用到fp16等半精度训练，需要安装nvidia的apex。 步骤： 先让两台机可以ssh通信，在主节点执行ssh-keygen，可以一直回车，生成的密钥在/home/你的用户名/.ssh/下，需要把公钥id_rsa.pub传到子节点的对应.ssh","title":"Deepspeed多机多卡训练记录"},{"content":"A Boring Guy\n","permalink":"https://boringleric.github.io/about/","summary":"A Boring Guy","title":"About"},{"content":"生活艰难\n","permalink":"https://boringleric.github.io/posts/life/life/","summary":"生活艰难","title":"Life"}]